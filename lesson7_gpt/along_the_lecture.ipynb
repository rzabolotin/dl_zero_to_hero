{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d718b3bc-0ae7-44e7-a4b7-1f805da00da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5fa51-021c-4e08-b17b-369a3e1c00e9",
   "metadata": {},
   "source": [
    "# Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a6757a-38e0-40fe-8217-50d597123aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../book.txt\", \"r\") as f_in:\n",
    "    book = f_in.read()\n",
    "    book = book[1681:] # remove special info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "252408a7-605a-4996-af09-20d22a0d32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \"NO PLACE LIKE HOME\"\n",
      "\n",
      "CHAPTER I.\n",
      "\n",
      "AN OLD HOVEL.\n",
      "\n",
      "THERE was not another home like it in all the parish of Broadmoor. It\n",
      "was a half-ruined hut, with walls bulging outwards, and a ragged roof\n",
      "of old thatch, overgrown with moss and yellow stonecrop. A rusty iron\n",
      "pipe in one corner served as a chimney to the flat hearth, which was\n",
      "the only fireplace within; and a very small lattice-window of greenish\n",
      "glass, with a bull's-eye in each pane, let in but little of the summer\n",
      "sunshine, and hardly a gleam of the winter's gloomy light. Only a few\n",
      "yards off, the hut could not be distinguished from the ruins of an old\n",
      "lime-kiln, near which it had been built to shelter the lime-burners\n",
      "during their intervals of work.\n",
      "\n",
      "There was but one room downstairs, with an earthen floor trodden hard\n",
      "by the trampling of heavy feet, whilst under the thatch there was\n",
      "a little loft, reached by a steep ladder and a square hole in the\n",
      "ceiling, where the roof came down on each side to the rough flooring,\n",
      "and nowher\n"
     ]
    }
   ],
   "source": [
    "print(book[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741e23a-1337-489a-bc44-d695bf3d4293",
   "metadata": {},
   "source": [
    "# Словарь и токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d683f198-a1bf-4428-9913-80cb9b594ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(\"\".join(book))), key=lambda v: \"\\t\" if v == \".\" else v)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12abc441-ca79-4eed-8e9d-fc184ef8c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {char: index for index, char in enumerate(vocab)}\n",
    "index_to_char = {index: char for char, index in char_to_index.items()}\n",
    "\n",
    "def tokenize(char):\n",
    "    return char_to_index.get(char, 0) \n",
    "\n",
    "def untokenize(index):\n",
    "    return index_to_char.get(index, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df99843-86d5-45b3-95c2-c51473091753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токен для буквы а 55\n",
      "Буква для токена 13 = -\n"
     ]
    }
   ],
   "source": [
    "print(f\"Токен для буквы а {tokenize(\"a\")}\")\n",
    "print(f\"Буква для токена 13 = {untokenize(13)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e9a20-a6e1-4640-b76c-6431c8d76f39",
   "metadata": {},
   "source": [
    "# Готовим данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eacc68c-9662-4249-a311-886b8228397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2,  ..., 1, 1, 1]) torch.Size([103137])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([tokenize(x) for x in book], dtype=torch.long)\n",
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88608fa-b6a6-43f0-9a7a-9e6b73921e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74ef765-f518-4ebb-b6cd-81772246b326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  2,  2,  2,  2,  2,  4, 41, 42,  2, 43])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 10\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482b0cd6-1285-462d-9847-2d58a8c3a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When X is tensor([2]) the y is 2\n",
      "When X is tensor([2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2, 2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2, 2, 2, 2]) the y is 4\n",
      "When X is tensor([2, 2, 2, 2, 2, 2, 4]) the y is 41\n",
      "When X is tensor([ 2,  2,  2,  2,  2,  2,  4, 41]) the y is 42\n",
      "When X is tensor([ 2,  2,  2,  2,  2,  2,  4, 41, 42]) the y is 2\n",
      "When X is tensor([ 2,  2,  2,  2,  2,  2,  4, 41, 42,  2]) the y is 43\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for i in range(block_size):\n",
    "    print(f\"When X is {x[:i+1]} the y is {y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f6d34b-f0e0-4379-a2a3-89d4bbb9246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "idx = torch.randint(len(train_data-block_size), (batch_size,))\n",
    "X = [train_data[i:i+block_size] for i in idx]\n",
    "Y = [train_data[i+1:i+block_size+1] for i in idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e0f9c2-a8a0-465e-b867-cad3143c0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size = 4):\n",
    "    data = val_data if split == \"valid\" else train_data\n",
    "    idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    X = torch.stack([data[i:i+block_size] for i in idx])\n",
    "    Y = torch.stack([data[i+1:i+block_size+1] for i in idx])\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06afb693-58f2-433f-8135-f15118723d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[79, 69, 75,  2, 77, 63, 66, 66,  2, 62],\n",
       "         [77, 62, 55, 74,  2, 62, 55, 58,  2, 62],\n",
       "         [72, 79,  2, 67, 63, 68, 75, 74, 59,  2],\n",
       "         [75, 67, 56, 12,  2, 55, 68, 58,  2, 69]]),\n",
       " tensor([[69, 75,  2, 77, 63, 66, 66,  2, 62, 55],\n",
       "         [62, 55, 74,  2, 62, 55, 58,  2, 62, 55],\n",
       "         [79,  2, 67, 63, 68, 75, 74, 59,  2, 67],\n",
       "         [67, 56, 12,  2, 55, 68, 58,  2, 69, 70]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980668ca-6c43-41c8-8c86-5861bb226335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 10])\n",
      "tensor([[58, 69, 69, 72,  1, 74, 69,  2, 66, 69],\n",
      "        [68, 58,  2, 62, 59,  8, 73,  2, 68, 69],\n",
      "        [46, 59, 59, 12,  2, 36,  8, 76, 59,  2],\n",
      "        [42, 62, 12,  2, 63, 60,  2, 36,  2, 74]])\n",
      "targets:\n",
      "torch.Size([4, 10])\n",
      "tensor([[69, 69, 72,  1, 74, 69,  2, 66, 69, 69],\n",
      "        [58,  2, 62, 59,  8, 73,  2, 68, 69,  2],\n",
      "        [59, 59, 12,  2, 36,  8, 76, 59,  2, 61],\n",
      "        [62, 12,  2, 63, 60,  2, 36,  2, 74, 62]])\n",
      "----\n",
      "when input is [58] the target: 69\n",
      "when input is [58, 69] the target: 69\n",
      "when input is [58, 69, 69] the target: 72\n",
      "when input is [58, 69, 69, 72] the target: 1\n",
      "when input is [58, 69, 69, 72, 1] the target: 74\n",
      "when input is [58, 69, 69, 72, 1, 74] the target: 69\n",
      "when input is [58, 69, 69, 72, 1, 74, 69] the target: 2\n",
      "when input is [58, 69, 69, 72, 1, 74, 69, 2] the target: 66\n",
      "when input is [58, 69, 69, 72, 1, 74, 69, 2, 66] the target: 69\n",
      "when input is [58, 69, 69, 72, 1, 74, 69, 2, 66, 69] the target: 69\n",
      "when input is [68] the target: 58\n",
      "when input is [68, 58] the target: 2\n",
      "when input is [68, 58, 2] the target: 62\n",
      "when input is [68, 58, 2, 62] the target: 59\n",
      "when input is [68, 58, 2, 62, 59] the target: 8\n",
      "when input is [68, 58, 2, 62, 59, 8] the target: 73\n",
      "when input is [68, 58, 2, 62, 59, 8, 73] the target: 2\n",
      "when input is [68, 58, 2, 62, 59, 8, 73, 2] the target: 68\n",
      "when input is [68, 58, 2, 62, 59, 8, 73, 2, 68] the target: 69\n",
      "when input is [68, 58, 2, 62, 59, 8, 73, 2, 68, 69] the target: 2\n",
      "when input is [46] the target: 59\n",
      "when input is [46, 59] the target: 59\n",
      "when input is [46, 59, 59] the target: 12\n",
      "when input is [46, 59, 59, 12] the target: 2\n",
      "when input is [46, 59, 59, 12, 2] the target: 36\n",
      "when input is [46, 59, 59, 12, 2, 36] the target: 8\n",
      "when input is [46, 59, 59, 12, 2, 36, 8] the target: 76\n",
      "when input is [46, 59, 59, 12, 2, 36, 8, 76] the target: 59\n",
      "when input is [46, 59, 59, 12, 2, 36, 8, 76, 59] the target: 2\n",
      "when input is [46, 59, 59, 12, 2, 36, 8, 76, 59, 2] the target: 61\n",
      "when input is [42] the target: 62\n",
      "when input is [42, 62] the target: 12\n",
      "when input is [42, 62, 12] the target: 2\n",
      "when input is [42, 62, 12, 2] the target: 63\n",
      "when input is [42, 62, 12, 2, 63] the target: 60\n",
      "when input is [42, 62, 12, 2, 63, 60] the target: 2\n",
      "when input is [42, 62, 12, 2, 63, 60, 2] the target: 36\n",
      "when input is [42, 62, 12, 2, 63, 60, 2, 36] the target: 2\n",
      "when input is [42, 62, 12, 2, 63, 60, 2, 36, 2] the target: 74\n",
      "when input is [42, 62, 12, 2, 63, 60, 2, 36, 2, 74] the target: 62\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa395e-86c0-422b-9bda-97ff76163ba3",
   "metadata": {},
   "source": [
    "# Bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1ea6e3-664c-4f97-8df6-bb2a7edad3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c32603-5473-49cc-a6fe-520c48b18815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, target = None):\n",
    "        logits = self.embedding(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "303ef0ef-bdb4-4dc4-a2eb-b3704c52900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d2301a-5bea-4e43-9d27-2926624d3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3fe667-3f54-4871-b855-0772adfdb878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[59,  2, 43, 72, 69, 64, 59, 57, 74,  2],\n",
       "         [55,  2, 57, 69, 70, 79, 12,  2, 69, 72],\n",
       "         [59, 58,  2, 62, 63, 73,  2, 59, 79, 59],\n",
       "         [ 2, 55, 66, 67, 69, 73, 74,  2, 73, 67]]),\n",
       " tensor([[ 2, 43, 72, 69, 64, 59, 57, 74,  2, 34],\n",
       "         [ 2, 57, 69, 70, 79, 12,  2, 69, 72,  2],\n",
       "         [58,  2, 62, 63, 73,  2, 59, 79, 59, 73],\n",
       "         [55, 66, 67, 69, 73, 74,  2, 73, 67, 69]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114d6e3-e19d-417a-a46b-663a78698357",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c159d00e-dc08-4258-8bbe-c7e644b81882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.AYk“I]&MUgm\" ’gNr(O-PBX\"MCEsD™&74npANc8NdWS‘E)h)CXJ)T6BsX7•\"2R5FC4*FIV““tN(!G:p5q7”T8I]r!hw0¹xn“p(&7'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "\"\".join([untokenize(x) for x in model.generate(prompt, 100).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4250315-563b-4d66-a1d1-8bc6ca6211ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.8tk’\\nK\\'O?(w\\'l3f%EBY‘3*iJQQoVoVr‘[F4a? (’-%Ean1.oi[OTA•Ac0YeK6l(c1\"P6::)H&Dh6*yM$d8TyII09I7oj[RaCguo%'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d70e1-0264-4a7c-b178-3e25ff393445",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30415ba6-74cc-40a9-b0bc-b55217333d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c1a62ca-421f-44ee-b68d-433012a65aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8482327461242676\n",
      "CPU times: user 6.92 s, sys: 15.1 ms, total: 6.93 s\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(1000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c72db9b5-a5a5-4dd1-a473-79b82c5bf585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".”¹6Wtea)’qzahVxhY!nr?7e,$)‘hYpt Hub\n",
      "•v—:g‘5L0—•9Y;xr*&BP:-zx\"h%EO’\"My6 (“Q;W”n1NrIMwB¹’aQIdf;wcaIwX'viWb(\"MR\n",
      "\n",
      "ugn)P2AYpr/d,KP)w\" Ygay:0UT&S!n“hJG7™BY![FRtkNO q•c¹%Gg!IEx\"HieL*91NfdoUu.!*QOQBEAHDi.wKoly,Kp,XowVkfUL4“BE\n",
      "KjQgsqt'a—ep5h%-4CLGGjF‘D9QOS.L%uK9Ov3Te,$1.v;$A&Vi,q1Dn1-•!V*1oj7OR7,An1A9BY.qQeweown1\"cuica1AckGSpFDh’LWP4Pad’?NDho *[\"inY’PL—pdca.S—-luG\"&)Y!y[isBYPsXy%9)lMO.\"bJ f!7&i(SaxUVobumyMlidw.ss\n",
      "¹Hib¹DnK¹2?[Q;W59x•9™9da—.u.7')4M]2,q(50‘Db[(/nw]Jr7(“4P[p\n",
      "m(V$2TXW\n",
      "[64—iANorQgw™.”?hH\n",
      "K.E™ ciV!qREr\"\n",
      "TExaJ]\n",
      "He\n",
      "c1\"JrD•YY$(R\n",
      "\"FUW”n•gJ™,DTuge OtI4;knH”(AOtECean;w”ghv™caim™MH:rH&aY$'E9?”p ba;WNdor“Jw]53*QsoyM(A—-FK™b)bRpxN\"Xo/UYEMRRgasQxFin1n¹) ha-C%)qv/ozv”p0\"BYGO9lR::794aI4N::1QnHN!1;9™\n",
      "F¹.1Aaz)RBHM2O]/¹T”e\"crPyQE/“&7oBsaT/,qXCTV&BiPqu b™4YtI2$O”4No?™U*93D]r‘xVc)1,f' e(.)k3Qx9JFU*K?\"\n",
      "wLo]&h6X’JDSow™,q•;WN BJ4HBYE•ru?‘NANo4hrT/(’’R5Lonbm csas op¹$tIB&.TarT853z?G0mar?I\n",
      "Y]u;Kp*OQ2AY'lllatdll&umyGO-$ dSUgJ4¹u9™f?%mP$T'O5ad!ak—xTK“g.fee\n",
      "f%VND'2XturpndjSdRE\n",
      "4ga)yeas',em$9DJ NrS.NOQT%Ks *Ob\n"
     ]
    }
   ],
   "source": [
    "print(model.generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38d834-989b-4880-bfe7-c7cafadc5945",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4206c96e-257d-440d-b596-4de931c8bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, neval = 20):\n",
    "    model.eval()\n",
    "    scores = {}\n",
    "    for split in ['train', 'valid']:\n",
    "        loss = 0\n",
    "        for i in range(neval):\n",
    "            X, Y = get_batch(split, batch_size=32)\n",
    "            _, loss_i = model(X, Y)\n",
    "            loss += loss_i.item()\n",
    "        scores[split] = loss / neval\n",
    "    model.train()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e624163-dae7-4406-ac42-b349dec42216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 3.8952, valid 4.1007\n",
      "Loss train: 3.8194, valid 4.0464\n",
      "Loss train: 3.7274, valid 3.9387\n",
      "Loss train: 3.6536, valid 3.8719\n",
      "Loss train: 3.5703, valid 3.8107\n",
      "Loss train: 3.4992, valid 3.7539\n",
      "Loss train: 3.4335, valid 3.7034\n",
      "Loss train: 3.3863, valid 3.6449\n",
      "Loss train: 3.3242, valid 3.5696\n",
      "Loss train: 3.2148, valid 3.5288\n",
      "3.1596169471740723\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        scores = evaluate_model(model)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48caa51a-caeb-474c-bec4-b588b7c9ffb3",
   "metadata": {},
   "source": [
    "# The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1366f62e-6490-4778-bd5f-2f658e704de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7015ac37-0b82-4584-8455-7c5e07213cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17c70176-95ba-45e4-8b95-8c87f486c0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "129ee1be-9523-4243-8648-507c651d8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4abd553-5e00-46fb-aa47-bad9cb76eb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2, rtol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c41f9b6f-9f08-4374-9bd0-0f71bd88df12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e621d79e-07d5-4a90-81a6-4f7c2c1c8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18404e4f-99cd-482c-99dd-ea354ef30934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a single Head perform self-attention\n",
    "head_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "426acee5-87be-4c3c-89b8-57fadb477e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96e8f2e3-71ef-4be3-b1ce-84d3ddb0dd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[ 0.1196, -0.3013,  0.3629,  1.1771,  1.1385, -0.2554,  0.1454, -0.2944,\n",
       "          -0.7020, -1.0308,  0.7436, -0.8098, -0.6669,  0.0912, -0.0061,  0.1983],\n",
       "         [-0.5423, -0.5558, -0.0761,  1.2929,  0.8653, -1.1998,  0.3878,  0.1939,\n",
       "           0.7024, -0.8225,  0.2348, -0.8499, -0.3813, -0.2991,  0.0102, -0.5545],\n",
       "         [-0.3736, -0.4678, -0.2156, -0.8034, -0.3715, -0.5443, -0.9146, -0.0559,\n",
       "          -0.3290, -0.2102,  0.1166, -0.1798, -0.2820, -0.3320, -0.4596, -0.1325],\n",
       "         [-0.3146,  0.0845, -0.1235, -0.7058, -0.1802,  0.5492, -0.8980, -0.4938,\n",
       "           0.6791,  0.8827,  0.4911,  0.5190,  0.9011,  0.0913, -0.1933, -0.6770],\n",
       "         [ 0.0239,  0.0998, -0.1871, -0.0860, -0.4881, -1.6765,  0.2413,  0.7361,\n",
       "           0.4608, -0.8722, -0.4259, -1.1347, -1.0571, -0.9401,  0.1343, -0.0157],\n",
       "         [-0.2362, -0.7873, -0.3802,  0.5815, -0.3722,  1.2405, -0.7004, -1.4917,\n",
       "           0.7678,  0.3584,  0.6120, -0.0794,  0.5983,  0.2635,  0.6490,  0.0709],\n",
       "         [-0.7941, -0.1660, -0.2810, -0.1021, -0.7352, -0.7518, -0.1276, -0.0051,\n",
       "           0.3325, -0.3374,  0.1678,  0.3105,  0.2258,  0.1243,  0.4617,  0.2016],\n",
       "         [ 0.1651, -0.1599, -0.5717, -0.3957,  0.3930, -0.8567,  0.3390, -0.7977,\n",
       "           0.2213, -0.5161,  0.1850, -0.2105,  0.3779,  0.0482, -0.4744, -0.0504]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = key(x)   # (B, T, 16)\n",
    "k.shape, k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31e97e6e-04e9-4f44-9be4-4bb2d4282196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[-0.6567,  0.0283,  0.0094, -0.6995, -0.3604,  0.8376, -0.4446,  0.1228,\n",
       "           0.6276, -0.6222,  0.3483,  0.2411,  0.5409, -0.2605,  0.3612, -0.0436],\n",
       "         [-0.3932,  0.8220, -0.7027,  0.0954, -0.1222, -0.1518, -0.5024, -0.4636,\n",
       "           0.1176,  1.4282, -0.5812,  0.1401,  0.9604,  0.0410, -0.6214, -0.6347],\n",
       "         [ 0.2157, -0.3507,  0.0022,  0.4232, -0.2284, -0.0732, -0.3412,  0.9647,\n",
       "          -0.5178,  0.0921, -0.5043,  0.8388,  0.6149, -0.0109, -0.5569,  0.5820],\n",
       "         [ 0.9000, -0.1272,  0.5458,  0.4254, -0.4513, -0.0212,  0.1711,  0.2599,\n",
       "          -0.9978,  0.4890,  0.1737, -0.0700, -0.3113,  0.3748, -0.1848, -0.6379],\n",
       "         [ 0.0332,  0.5886, -0.4437,  0.3775, -0.6826, -0.2775,  0.4673, -1.2956,\n",
       "           0.6603,  0.1633, -1.7573, -0.6582, -0.2302, -0.0862, -0.0060,  0.7573],\n",
       "         [ 0.2098,  0.0439, -0.0702,  0.0727, -0.2012, -1.7539,  1.0369,  0.1163,\n",
       "           0.2956,  0.3231,  0.5052,  0.7011, -0.2844, -0.7844,  0.4782, -0.5170],\n",
       "         [ 0.6100, -0.3284, -0.8557,  0.8543,  0.7805, -0.4023, -0.8183, -0.0554,\n",
       "           0.1873,  0.2706, -0.7066, -0.8637,  0.6998, -0.0670,  0.2551,  0.2149],\n",
       "         [ 0.1459,  0.1349, -0.2335, -0.0417,  0.2928, -0.5080,  0.1177,  0.1861,\n",
       "           0.1455,  0.0292, -0.8470,  0.6116,  1.2445,  0.1909,  0.3694, -0.0027]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = query(x) # (B, T, 16)\n",
    "q.shape, q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff25d5a6-7cfb-4fc2-9539-c9b5879d8f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8]),\n",
       " tensor([[-0.7353, -1.7807,  1.0745, -0.2743,  1.6347,  1.4177, -0.5521, -2.3580],\n",
       "         [-3.0892, -1.4943, -0.2617,  2.2760, -0.2436,  0.1620,  2.5783,  0.3959],\n",
       "         [-0.5021, -2.0745,  0.5379, -0.4049,  0.8329,  1.3570, -1.5621, -1.6490],\n",
       "         [ 1.3810, -0.1471,  1.2181, -0.2227, -1.8247, -3.7044, -2.1321,  1.3178],\n",
       "         [-2.3568, -0.4617, -0.8820,  2.3700,  0.6783,  0.1626,  1.9379,  0.1040],\n",
       "         [-0.9243, -0.6235, -1.3938,  1.3336, -0.0090, -3.1789,  0.9026,  3.6256],\n",
       "         [-0.6552,  1.0991, -2.1399,  0.9647,  0.9946,  0.9390,  0.4680, -0.3587],\n",
       "         [ 1.5463, -0.4944, -0.0142, -0.9743,  1.3779,  0.0079, -0.5359, -0.4553]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "wei.shape, wei[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31314b54-5ef0-48e0-bd2a-e8fef6b35cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8]),\n",
       " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "wei.shape, wei[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fcc66ed-149a-4d2a-af8b-e9e649d97286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[-1.3254e+00,  1.1236e+00,  2.2927e-01, -2.9970e-01, -7.6267e-03,\n",
       "           7.9364e-01,  8.9581e-01,  3.9650e-01, -6.6613e-01, -2.1844e-01,\n",
       "          -1.3539e+00,  4.1245e-01,  9.6011e-01, -1.0805e+00, -3.9751e-01,\n",
       "          -4.4439e-01],\n",
       "         [-1.9221e-01, -4.6449e-01,  5.9880e-02,  2.8408e-01, -1.0312e-01,\n",
       "          -1.7967e-03,  1.8920e-01, -3.7337e-01, -9.8137e-02,  2.3116e-02,\n",
       "           8.5743e-01,  5.6841e-01, -2.1939e-01, -2.9158e-01, -2.0158e-01,\n",
       "          -4.6876e-01],\n",
       "         [-1.1012e+00,  9.8266e-02,  5.8596e-01, -5.6413e-03,  3.7330e-01,\n",
       "          -6.1363e-02,  2.8833e-02,  2.6230e-01,  6.4099e-01,  7.1003e-02,\n",
       "           3.6877e-01,  5.0011e-01,  7.3872e-01,  1.1909e-01,  5.4246e-01,\n",
       "           6.8950e-02],\n",
       "         [ 4.9074e-01, -2.9978e-01,  1.0949e+00,  1.0131e+00,  3.5883e-01,\n",
       "           9.5771e-01, -1.8349e-01,  1.4002e-01,  1.4243e-01,  8.0787e-01,\n",
       "          -2.4476e-01,  1.3392e-01,  2.6700e-01,  3.2605e-01,  2.0296e-01,\n",
       "           1.4967e-01],\n",
       "         [ 4.5700e-02,  1.0993e+00,  4.6545e-01, -1.5803e-01, -7.2921e-01,\n",
       "           5.8145e-01,  4.0171e-01,  1.3040e+00, -2.2263e-02,  3.9847e-01,\n",
       "           6.3218e-01, -1.4205e-01,  5.0596e-01, -2.9585e-01, -3.5306e-02,\n",
       "          -7.2087e-01],\n",
       "         [ 3.6249e-01,  3.1444e-01,  3.7844e-01, -3.3100e-01, -1.1213e+00,\n",
       "          -6.8686e-01, -6.5431e-01, -2.1805e-01, -2.6552e-01,  6.7712e-01,\n",
       "           3.9176e-01, -1.3338e+00,  3.7350e-01, -1.1095e+00,  3.7270e-01,\n",
       "          -9.3442e-01],\n",
       "         [-2.0881e-01, -7.6620e-02, -1.5674e-01,  1.4457e-01,  8.7035e-01,\n",
       "           2.1136e-01, -4.8995e-01,  2.4986e-01,  5.1811e-01,  6.6507e-01,\n",
       "           3.2814e-01,  4.6015e-01,  9.2321e-01, -4.5579e-01, -4.8577e-01,\n",
       "          -2.7199e-01],\n",
       "         [-1.8408e-01,  1.7347e-01,  1.4034e-02, -4.8221e-01, -5.2118e-01,\n",
       "          -2.6668e-01, -1.0874e-01,  2.0809e-01,  3.0165e-01,  5.3594e-02,\n",
       "          -3.7746e-01, -7.4163e-01,  8.8692e-04, -1.2250e+00,  3.0022e-01,\n",
       "          -5.0357e-01]], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = value(x)\n",
    "v.shape, v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "842c5aca-200d-4f0d-a853-b25f466c86ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a7a65-d788-4fbd-b5fb-4ea9c4515075",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "* There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "* Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "* In an \"encoder\" attention block just delete the single line that does masking with tril, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "* \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "* \"Scaled\" attention additional divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3d168d9-67de-4cd6-90b4-32abd71d2860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9857, -1.7370,  0.4189,  0.2985, -0.5451,  0.4942, -0.7267,\n",
       "          -0.4810],\n",
       "         [-0.6151,  0.7704,  0.1215,  0.1193, -1.0559, -0.1234,  0.3918,\n",
       "          -0.2687],\n",
       "         [ 0.4511,  0.6600,  0.8736, -0.5065,  0.8595,  0.2483,  0.7095,\n",
       "          -0.3241],\n",
       "         [ 1.4350, -0.5599,  1.2163, -0.0813,  1.7313,  0.3421, -0.3146,\n",
       "          -0.9178],\n",
       "         [-2.0204,  1.8716, -1.1214, -0.1317, -0.4320,  0.8461,  1.0991,\n",
       "           1.8651],\n",
       "         [ 1.0000,  0.5394,  0.9807, -0.0900,  0.7364,  1.3018,  1.4779,\n",
       "           1.2385],\n",
       "         [ 1.0542, -0.5249,  0.1258, -0.0781,  0.8236, -1.0546,  0.3601,\n",
       "          -0.5679],\n",
       "         [ 0.2587,  0.1620,  0.6471,  0.2837,  1.2641,  0.3890, -0.6218,\n",
       "          -0.4601]],\n",
       "\n",
       "        [[ 0.2958,  0.3852, -0.7456,  0.0486, -0.1722, -0.3054,  0.8299,\n",
       "           0.4364],\n",
       "         [-0.8550,  0.2635,  1.0761,  0.9544,  0.7529, -0.9505,  0.2712,\n",
       "          -0.7474],\n",
       "         [-0.9295, -0.1556, -0.0649, -0.3967, -0.1137, -1.0016,  0.5251,\n",
       "           2.1469],\n",
       "         [ 0.4260,  0.5476, -0.1825,  0.4262,  0.4614,  0.7707, -0.0319,\n",
       "           0.0419],\n",
       "         [ 0.9852, -1.8435,  0.5392,  0.9052,  0.0147, -0.0083, -0.3682,\n",
       "          -1.4787],\n",
       "         [ 0.0243, -0.7921,  1.1611, -2.1399,  0.8785, -3.7707,  0.2854,\n",
       "           0.2840],\n",
       "         [ 1.2051,  0.7425,  0.1625,  0.1487, -0.3684,  1.1103, -0.6565,\n",
       "          -0.5399],\n",
       "         [ 0.4974, -0.6444, -0.5425,  1.1529,  1.4586,  2.1972, -1.4472,\n",
       "          -2.8702]],\n",
       "\n",
       "        [[ 0.8568,  2.0571, -0.7006,  0.3831,  0.3106, -0.0532, -0.3264,\n",
       "          -1.9622],\n",
       "         [ 0.2715,  1.6624, -1.0427,  0.8949,  0.9935, -1.7049, -0.6244,\n",
       "          -0.0398],\n",
       "         [-0.2850, -1.0568,  1.0730, -0.3639,  1.4113,  0.4204,  0.0832,\n",
       "           1.8698],\n",
       "         [ 0.2770, -0.6132,  0.0788, -0.9589,  0.1094, -0.6141,  0.2004,\n",
       "          -1.6000],\n",
       "         [-0.6044,  0.2721,  2.6773, -0.6017,  0.0375, -1.9897, -0.9305,\n",
       "           0.2045],\n",
       "         [ 0.1326,  1.4459,  0.4910,  0.8230,  0.4905, -0.6744,  0.1504,\n",
       "           0.7052],\n",
       "         [ 0.9300,  0.8989, -0.2437,  1.2802,  1.8367, -1.6352,  1.1763,\n",
       "          -1.7056],\n",
       "         [-0.6255,  0.1929,  0.2220, -1.3950,  1.2366, -0.2456,  1.7097,\n",
       "           0.0183]],\n",
       "\n",
       "        [[ 0.7970, -0.1589,  2.1649,  1.3842,  1.0258, -0.0408, -0.9887,\n",
       "          -2.0557],\n",
       "         [-0.8892,  1.2347, -1.0261,  0.4946, -0.5050,  0.4870,  0.8439,\n",
       "           0.4716],\n",
       "         [-0.3764,  0.7035,  1.2153,  2.7291, -0.8751,  1.2909, -0.0223,\n",
       "          -2.2251],\n",
       "         [-3.0034, -0.0472, -1.8734,  0.4687,  1.1202,  0.0969,  1.7634,\n",
       "           0.6773],\n",
       "         [-0.8947, -0.0660, -1.8381,  0.0621, -0.6480, -0.0997,  0.6156,\n",
       "           0.9758],\n",
       "         [ 0.1174, -0.0431, -0.3131, -1.1377, -0.2750,  0.2928,  0.8689,\n",
       "           1.4676],\n",
       "         [-0.1954,  0.3430,  0.8964, -0.2087,  0.9346, -0.0980,  0.7557,\n",
       "          -0.7743],\n",
       "         [ 2.0831,  0.4608,  4.1820, -0.3133,  1.4190,  1.7620,  0.2617,\n",
       "          -1.2753]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1001fd-3b0e-4ddb-aac1-afbf723727bc",
   "metadata": {},
   "source": [
    "# Model 2 + position encoding and linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9971c284-861c-44a3-b6c2-21e308700ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 32\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_emgeding = nn.Embedding(block_size, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, target = None):\n",
    "        B,T = idx.shape\n",
    "        token_embed = self.token_embedding(idx)\n",
    "        position_embed = self.position_emgeding(torch.arange(block_size))\n",
    "        x = token_embed # + position_embed\n",
    "        logits = self.lm_head(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a741c1f-b201-40eb-b74d-271aabeb1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model2(vocab_size) \n",
    "optimizer2 = torch.optim.AdamW(model2.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93f9137c-5b6b-4e64-b5ba-9ef33185908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 4.5434, valid 4.5847\n",
      "Loss train: 3.2354, valid 3.6357\n",
      "Loss train: 2.8871, valid 3.3518\n",
      "Loss train: 2.7644, valid 3.3977\n",
      "Loss train: 2.7748, valid 3.4381\n",
      "Loss train: 2.7295, valid 3.3741\n",
      "Loss train: 2.7385, valid 3.4593\n",
      "Loss train: 2.7196, valid 3.5232\n",
      "Loss train: 2.6996, valid 3.8257\n",
      "Loss train: 2.8132, valid 3.6644\n",
      "3.261875867843628\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model2(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "    if i%100 == 0:\n",
    "        scores = evaluate_model(model2)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c70e4-7663-4637-93da-a6642364b247",
   "metadata": {},
   "source": [
    "# Single head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3803581-0680-4197-a6f9-b78f8fc2044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, head_size, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ea4fb29-1031-42d1-b34a-0885cf67e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    \"One attention head\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_emgeding = nn.Embedding(block_size, n_embed)\n",
    "        self.sa_head = Head(n_embed, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, target = None):\n",
    "        B,T = idx.shape\n",
    "        token_embed = self.token_embedding(idx)\n",
    "        position_embed = self.position_emgeding(torch.arange(T))\n",
    "        x = token_embed + position_embed\n",
    "        x = self.sa_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2cbef54-1b03-40d2-be40-6dd34886fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Model3(vocab_size)\n",
    "optimizer3 = torch.optim.AdamW(model3.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4268f84-ae83-40a7-802c-1915863bc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 4.4852, valid 4.4892\n",
      "Loss train: 3.1141, valid 3.7331\n",
      "Loss train: 2.8913, valid 3.3110\n",
      "Loss train: 2.7057, valid 3.2623\n",
      "Loss train: 2.6071, valid 3.2589\n",
      "Loss train: 2.5828, valid 3.2975\n",
      "Loss train: 2.6020, valid 3.1633\n",
      "Loss train: 2.6052, valid 3.2499\n",
      "Loss train: 2.6161, valid 3.3041\n",
      "Loss train: 2.6136, valid 3.3110\n",
      "2.629554271697998\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model3(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer3.step()\n",
    "    if i%1000 == 0:\n",
    "        scores = evaluate_model(model3)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5c4db46-65bf-4101-9481-35457db3a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "earkar, herero l'thethe tg\n",
      "\" t winy h tthe ss helindeey ulnceh elyes be t s t\n",
      "eer h t hey He f m in'\n",
      "\n",
      "int\n",
      "k st ve hag—t her e r himirthic t wosece st fof handath ie t\n",
      "\"Sthithe ag of theanthe thean nth f t s o he by; are he seid,\"Is s.\"III\n",
      "sstakee he.\n",
      "onthid heroby own h, \"Aveey h oke f t w \n",
      "\"Rure t got ch hrot. sh thee he\n",
      "\n",
      "f knt textre'st d ly  is ce wore fe'squler,\n",
      " ofellyle wint g a  winy il.\"\n",
      "we urde t yeo fielas.\n",
      "\n",
      "hon omimine s otht, or\n",
      "t Re e\n",
      "\"edit t gineellon hid\n",
      "\n",
      "d un taifotles ave't\n",
      "c t t frmer wefouig t\n",
      "fof ay h minet w\n",
      "ly ssimaieit hereld a ar t s n, icha t d bet orede n hega eeeng s busoug, on hee s o sofue ng oto fofer,\n",
      "\n",
      "\n",
      "l's ca orma et an ks hanoyshtys 's m. tlmiscar bye ss whereanthoorowh fe' sto wen ry fourextro helileg imeg,\" big asther\n",
      "west as t rofems s's od tths.\n",
      "oth g sh carerot an s h at cld a s.\"\n",
      "\n",
      "\"Ave\n",
      "nsslle goy the sthimibeorae d t  orof hodl plmad triallung oimonde croor, heashris hent fon shot.\"llldse htt thas malllyemor be  becr; t r te h sthe'd s,\n",
      "\n",
      "'sseath\n"
     ]
    }
   ],
   "source": [
    "print(model3.generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761a61f-eac3-4e98-bd4f-5399cb25ddf2",
   "metadata": {},
   "source": [
    "# Multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8471073c-fcd9-4c24-b424-7c0a147164a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_embd, head_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = [Head(n_embd, head_size) for _ in range(num_heads)]\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "745c710f-7c90-4f52-ace5-33008802fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    \"Multihead\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_emgeding = nn.Embedding(block_size, n_embed)\n",
    "        self.sa_head = MultiHeadAttention(n_embed, n_embed//4, 4)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, target = None):\n",
    "        B,T = idx.shape\n",
    "        token_embed = self.token_embedding(idx)\n",
    "        position_embed = self.position_emgeding(torch.arange(T))\n",
    "        x = token_embed + position_embed\n",
    "        x = self.sa_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b8bc333-d0ea-4bc5-a909-8c3565475e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Model4(vocab_size)\n",
    "optimizer4 = torch.optim.AdamW(model4.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ca5a920-3498-4bfe-bb59-87cab9a995fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 2.5529, valid 3.3762\n",
      "Loss train: 2.5478, valid 3.3043\n",
      "Loss train: 2.5842, valid 3.4124\n",
      "Loss train: 2.5273, valid 3.5445\n",
      "Loss train: 2.5023, valid 3.1714\n",
      "Loss train: 2.4843, valid 3.3167\n",
      "Loss train: 2.4943, valid 3.3946\n",
      "Loss train: 2.4761, valid 3.4232\n",
      "Loss train: 2.4848, valid 3.2340\n",
      "Loss train: 2.4688, valid 3.2339\n",
      "2.4572887420654297\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model4(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer4.step()\n",
    "    if i%1000 == 0:\n",
    "        scores = evaluate_model(model4)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b98f881-9089-4960-8d9a-325021f4b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "' wose\n",
      "wort maigousnmke evere l Jecoe afriwoipim, operwo tsho rf, ave an Is winglga riet hererea thim. sd Sor. Difier Hro?\"\n",
      " al whfart cuman ouswi tflaer\n",
      "ayve o yr uin wou, an ghaflind othe  chem imap goirs; amen, in. —hernm APR—————ghe y's in.\n",
      "Bugot\n",
      "rod wauit no?\"\n",
      "\"Soe h e theenwh lak, wet, what ly nothe f wonuthot the nd Iss sof ris's\n",
      "sithe toufr.\n",
      "\n",
      "Ruuthirl, ar atois thinluer ad y ny thud ny ind ntwepende pateresend y woe efurdartof; onel!\" r ochea fom.\" aI tanbpay, ary, andas of yan bthendoun indy ghe Igthe h Mas' fot day s Pl ghey ra f bforrmuy she —f Ila whse.\n",
      "\n",
      "\n",
      "athum nd y whet areerd foeuninowthe f Hushe lousle ftor; es\n",
      "sgot ares tnelal themary an he an Mal, day, f fowo rfof.\"\n",
      " It moa ld irlemat dad ecowreaye bwe he bals ky poome wereriver amer aofther. Ha w whainno. Nucuchellterswy soseo homourse doxaf, sotokec\n",
      "o h [Isltha THE. Th. THhee tro\n",
      "u farcose ak bryy-isnokou ptl; helsanoy olal gy iy fubiny  the swan pthain f woy uberutrtok, wh rauk rine.\n",
      "Ye t, apterver.\n",
      "\n",
      "M\"Rby  Wougly \n"
     ]
    }
   ],
   "source": [
    "print(model4.generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bde6c-d16d-4d68-a380-004b6c43ea31",
   "metadata": {},
   "source": [
    "# Add Feedforward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8e04060-72a2-496c-a5d0-7ef28c2c972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82fb792e-d85e-4e4d-9436-9ca4b3965484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model5(nn.Module):\n",
    "    \"+ Feedforward\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_emgeding = nn.Embedding(block_size, n_embed)\n",
    "        self.sa_head = MultiHeadAttention(n_embed, n_embed//4, 4)\n",
    "        self.ff = FeedFoward(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, target = None):\n",
    "        B,T = idx.shape\n",
    "        token_embed = self.token_embedding(idx)\n",
    "        position_embed = self.position_emgeding(torch.arange(T))\n",
    "        x = token_embed + position_embed\n",
    "        x = self.sa_head(x)\n",
    "        x = self.ff(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a0d2adf-969e-4d5a-8a5c-c6256f4d6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Model5(vocab_size)\n",
    "optimizer5 = torch.optim.AdamW(model5.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84768867-7d50-4fcb-b6a4-26b37f373941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 2.5692, valid 3.1145\n",
      "Loss train: 2.4836, valid 3.1331\n",
      "Loss train: 2.4724, valid 3.1017\n",
      "Loss train: 2.5154, valid 3.1178\n",
      "Loss train: 2.4885, valid 3.0177\n",
      "Loss train: 2.4765, valid 3.1613\n",
      "Loss train: 2.4704, valid 3.2122\n",
      "Loss train: 2.4608, valid 3.1457\n",
      "Loss train: 2.4468, valid 3.1231\n",
      "Loss train: 2.4278, valid 3.1349\n",
      "2.4023804664611816\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model5(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer5.step()\n",
    "    if i%1000 == 0:\n",
    "        scores = evaluate_model(model5)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb5d4ae9-3e3b-4bb8-a4da-c278139d02ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "CGutecatt uit hinemr, aang Gacicllgucopang e she mutee forler bomeny ther ase aitlat itherir theang hif thest abypatos ther satits beroler albe aeg cutha m miteey\n",
      "nint-ru wriblteyned ongttuo huge, r ashey thee adtakd \"wit icitw me thay\n",
      "iunoren stoif srwe. Nwe wod nallyk\n",
      "taf hisn yohe shan'w the tit o Ge then lias overeren bepslow, ooud wat bobenod sshe coundict 1eith sen hee omy owo' bmof meou us th theerr; e lon as dof od wac ton'rogtthe the bithelap wing whaver\n",
      "lit\n",
      "eebetd wied sporacofto y, ba the they swo waly'en aft ase hrerspu oclleld fingg st'elt fiowlloro'P asens ur yhe hir, ang long ssi thany towe Wo chawl the ce actde. I Hoorngtoup, he chof to ma traze de beyfy fapa wro, dould k'lewwe\n",
      "ghlitsting hee\n",
      "she anacrrouf of sies t therealy bey thies, tree tichen'tte a aend co astllingf\n",
      "eme\n",
      "swas\n",
      "coth med caslta hei e warhey ther ayid teme smeraeds ared herrey yound indingreren, wes,\" a arat sing the sbe to lery su mond, lelevoral, tayd  rook\n",
      "dtoo herladnguS. Ats\n",
      "B Hiteechene, hive ars\n"
     ]
    }
   ],
   "source": [
    "print(model5.generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e25a9-af8f-4502-b01f-57999690488a",
   "metadata": {},
   "source": [
    "# Introduce blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59966c46-8e7b-4a7e-adf4-2887f4cb0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention2(nn.Module):\n",
    "    def __init__(self, n_embd, head_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = [Head(n_embd, head_size) for _ in range(num_heads)]\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad876e91-2fb3-43ff-89d1-26f18fed2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_heads):\n",
    "        super().__init__()\n",
    "        self.heads = MultiHeadAttention2(n_embed, n_embed//n_heads, n_heads)\n",
    "        self.ff = FeedFoward(n_embed)\n",
    "    def forward(self, x):\n",
    "        x = x + self.heads(x)\n",
    "        out = x + self.ff(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "821a904b-423a-49b9-90a2-0b06054a7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model6(nn.Module):\n",
    "    \"+ blocks\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_emgeding = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embed, 4),\n",
    "            Block(n_embed, 4),\n",
    "            Block(n_embed, 4)\n",
    "        )\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, target = None):\n",
    "        B,T = idx.shape\n",
    "        token_embed = self.token_embedding(idx)\n",
    "        position_embed = self.position_emgeding(torch.arange(T))\n",
    "        x = token_embed + position_embed\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ada08b8-f69b-4609-ac93-41cd6389dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Model6(vocab_size)\n",
    "optimizer6 = torch.optim.AdamW(model6.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32977bb7-d933-4c05-a1d1-c9e8f6de5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 2.4685, valid 3.4950\n",
      "Loss train: 2.4905, valid 3.5867\n",
      "Loss train: 2.4494, valid 3.7298\n",
      "Loss train: 2.4862, valid 3.5445\n",
      "Loss train: 2.4617, valid 3.4688\n",
      "Loss train: 2.4670, valid 3.5610\n",
      "Loss train: 2.4318, valid 3.4274\n",
      "Loss train: 2.4597, valid 3.5924\n",
      "Loss train: 2.5002, valid 3.8630\n",
      "Loss train: 2.4351, valid 3.4708\n",
      "2.476980447769165\n"
     ]
    }
   ],
   "source": [
    "m = model6\n",
    "o = optimizer6\n",
    "for i in range(10000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = m(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    o.step()\n",
    "    if i%1000 == 0:\n",
    "        scores = evaluate_model(m)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee0368b3-e6ac-4a77-b95f-ee52db5c1327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".S I brhem. \n",
      "irelo che neritha d her of and oulllang come cribe oe che o coll bat thee he sereris tss orely il. hag\n",
      "\n",
      "ag\n",
      "\n",
      "shae s hay oringhe hemang\n",
      "Iif thele fof, rack nel? on \"\n",
      "\n",
      "he s hacre  ssael s e afit ereraing\n",
      "ss kenou tomeler Te'\n",
      "\n",
      "f Iinct aplofuld s ars\" if to ngo ste awer ha m\n",
      "he Het ale I'm heved \n",
      " an' arcrand oo nthild harle wad, glin. t lort to  idshicther onl,, y\n",
      "and ay, anll\n",
      "he ithes Ar uing ae porp r'srerkr, an tarind t anthe e wanbes\n",
      "\n",
      "as e it args olit ath tean cot ilir thes he ano t s athe ten,\n",
      "and adh are. \n",
      "o\n",
      "tor cche s l as\" \n",
      "\n",
      "r an\n",
      "tie\n",
      "\n",
      "at \n",
      "ad p livegr tollo hees t allin cand ive'l was no d lf anthee \" saek fr cay Hed\n",
      "\n",
      "he Ye.\n",
      "\n",
      "\"Suped here hror, s oothe \n",
      "es hed laen s I boik ts. peand yoto'ie s.\n",
      "s \n",
      "And\n",
      "an \n",
      "an\n",
      "\n",
      "acawicch she h \n",
      "a astin wan ad ive\n",
      "a  grin mshe acp aneile\n",
      "\n",
      "\n",
      "forch s rye fid, reis; onk ned mmit y 'sore in loris le hasom see oif.\n",
      "hee Her'wane t shing heanbat coun wou, wnt roh she, \n",
      "irg\n",
      "e se ughel se rif\n",
      "ove n Huing la, bertm o\n",
      "\n",
      "ag mar tol wate d ating a ton t r \n"
     ]
    }
   ],
   "source": [
    "print(m.generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb73b6-4d9d-4199-b714-5a9f0a5ea252",
   "metadata": {},
   "source": [
    "# Final architecture (from Andrej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6fb9b9f5-54ba-418d-8b04-9bb72da34a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "683df4dc-bf6f-4ab2-95a9-76e749724519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d8dc45a-75d7-42c3-9073-ff69a5532a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "befec183-eb78-4fa7-bacb-d5783d47252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa6c40d7-82c4-41f9-8858-dafed20a92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model7(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d03def5c-4d0c-4196-8a20-935ac1b1bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 32\n",
    "dropout = 0.2\n",
    "n_layer = 3\n",
    "n_head = 4\n",
    "device = 'cpu'\n",
    "\n",
    "model7 = Model7()\n",
    "optimizer7 = torch.optim.AdamW(model7.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4db1708e-c864-40b2-893e-4677bc40c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 2.4040, valid 3.0002\n",
      "Loss train: 2.3876, valid 2.9633\n",
      "Loss train: 2.3316, valid 2.9719\n",
      "Loss train: 2.3168, valid 3.0093\n",
      "Loss train: 2.3058, valid 2.9829\n",
      "Loss train: 2.2935, valid 2.8786\n",
      "Loss train: 2.2994, valid 2.8954\n",
      "Loss train: 2.2843, valid 2.9193\n",
      "Loss train: 2.2710, valid 2.8215\n",
      "Loss train: 2.2878, valid 2.8276\n",
      "2.2491660118103027\n"
     ]
    }
   ],
   "source": [
    "m = model7\n",
    "o = optimizer7\n",
    "for i in range(10000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = m(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    o.step()\n",
    "    if i%1000 == 0:\n",
    "        scores = evaluate_model(m)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d495a29a-eef3-4d80-9c77-9e8b7b656d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "., a ill sarrrolveravey high wacavideivagean'ser. Ishml cas sro prelthtw.\n",
      "\"Soventsineno dnce,\n",
      "lifore she fof, and, wad  orom \n",
      "ave band margem qum pivearor re song to inricfro cras forlgat he shin hing\n",
      "shaint shlouse freanthe, mored arvroe scaid bloof tren ut la wa'sexlllius wradeld, wals hererrer vlrn whe wyrreak ga thol! E\n",
      "shlot ald thaspast sEme aglidead houe leeigh fiche hof the himahe poor as omerow ied delt lach pit lan my his rrouscesan mat leder erored asy thericrer thart medng acengas of\n",
      "he wof hen ler his adeandark sowkee ated,\" thande hith sarenthe  bot her woup ing, vadroong. Whe heondrs\n",
      "incexh forsninge mundloume to manoreh, of  the s. I slat apt me nin.\n",
      "\"\n",
      "Isad Gufat lane hay bmim lan, eprand \n",
      "brewit hvah the gid thercen blys\n",
      "hind fred was of wheyt hirec as hus rrot hatomll tipn ive rrid tohas ass shalyes te and, waln dof a \"ores., Ho\n",
      "Liwos plant has hing, droow dar sheftord hen tht arelaced ler no whe wa arnl sow.'”'l anakm rof lorkn woubrineg7\"\n",
      "\n",
      "aod flof wor drlrprroucte,e\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 1000\n",
    "prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "print(\"\".join([untokenize(x) for x in m.generate(prompt, max_tokens).tolist()[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df19f27-1933-4137-a224-f331b6642894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
