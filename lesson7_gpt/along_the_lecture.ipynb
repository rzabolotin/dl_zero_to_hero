{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d718b3bc-0ae7-44e7-a4b7-1f805da00da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5fa51-021c-4e08-b17b-369a3e1c00e9",
   "metadata": {},
   "source": [
    "# Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a6757a-38e0-40fe-8217-50d597123aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../book.txt\", \"r\") as f_in:\n",
    "    book = f_in.read()\n",
    "    book = book[1681:] # remove special info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "252408a7-605a-4996-af09-20d22a0d32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \"NO PLACE LIKE HOME\"\n",
      "\n",
      "CHAPTER I.\n",
      "\n",
      "AN OLD HOVEL.\n",
      "\n",
      "THERE was not another home like it in all the parish of Broadmoor. It\n",
      "was a half-ruined hut, with walls bulging outwards, and a ragged roof\n",
      "of old thatch, overgrown with moss and yellow stonecrop. A rusty iron\n",
      "pipe in one corner served as a chimney to the flat hearth, which was\n",
      "the only fireplace within; and a very small lattice-window of greenish\n",
      "glass, with a bull's-eye in each pane, let in but little of the summer\n",
      "sunshine, and hardly a gleam of the winter's gloomy light. Only a few\n",
      "yards off, the hut could not be distinguished from the ruins of an old\n",
      "lime-kiln, near which it had been built to shelter the lime-burners\n",
      "during their intervals of work.\n",
      "\n",
      "There was but one room downstairs, with an earthen floor trodden hard\n",
      "by the trampling of heavy feet, whilst under the thatch there was\n",
      "a little loft, reached by a steep ladder and a square hole in the\n",
      "ceiling, where the roof came down on each side to the rough flooring,\n",
      "and nowher\n"
     ]
    }
   ],
   "source": [
    "print(book[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741e23a-1337-489a-bc44-d695bf3d4293",
   "metadata": {},
   "source": [
    "# Словарь и токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d683f198-a1bf-4428-9913-80cb9b594ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(\"\".join(book))), key=lambda v: \"\\t\" if v == \".\" else v)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12abc441-ca79-4eed-8e9d-fc184ef8c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = {char: index for index, char in enumerate(vocab)}\n",
    "index_to_char = {index: char for char, index in char_to_index.items()}\n",
    "\n",
    "def tokenize(char):\n",
    "    return char_to_index.get(char, 0) \n",
    "\n",
    "def untokenize(index):\n",
    "    return index_to_char.get(index, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df99843-86d5-45b3-95c2-c51473091753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токен для буквы а 55\n",
      "Буква для токена 13 = -\n"
     ]
    }
   ],
   "source": [
    "print(f\"Токен для буквы а {tokenize(\"a\")}\")\n",
    "print(f\"Буква для токена 13 = {untokenize(13)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e9a20-a6e1-4640-b76c-6431c8d76f39",
   "metadata": {},
   "source": [
    "# Готовим данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eacc68c-9662-4249-a311-886b8228397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2,  ..., 1, 1, 1]) torch.Size([103137])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([tokenize(x) for x in book], dtype=torch.long)\n",
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88608fa-b6a6-43f0-9a7a-9e6b73921e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74ef765-f518-4ebb-b6cd-81772246b326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  2,  2,  2,  2,  2,  4, 41, 42,  2, 43])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 10\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482b0cd6-1285-462d-9847-2d58a8c3a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When X is tensor([2]) the y is 2\n",
      "When X is tensor([2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2, 2, 2]) the y is 2\n",
      "When X is tensor([2, 2, 2, 2, 2, 2]) the y is 4\n",
      "When X is tensor([2, 2, 2, 2, 2, 2, 4]) the y is 41\n",
      "When X is tensor([ 2,  2,  2,  2,  2,  2,  4, 41]) the y is 42\n",
      "When X is tensor([ 2,  2,  2,  2,  2,  2,  4, 41, 42]) the y is 2\n",
      "When X is tensor([ 2,  2,  2,  2,  2,  2,  4, 41, 42,  2]) the y is 43\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for i in range(block_size):\n",
    "    print(f\"When X is {x[:i+1]} the y is {y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f6d34b-f0e0-4379-a2a3-89d4bbb9246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "idx = torch.randint(len(train_data-block_size), (batch_size,))\n",
    "X = [train_data[i:i+block_size] for i in idx]\n",
    "Y = [train_data[i+1:i+block_size+1] for i in idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e0f9c2-a8a0-465e-b867-cad3143c0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size = 4):\n",
    "    data = val_data if split == \"valid\" else train_data\n",
    "    idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    X = torch.stack([data[i:i+block_size] for i in idx])\n",
    "    Y = torch.stack([data[i+1:i+block_size+1] for i in idx])\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06afb693-58f2-433f-8135-f15118723d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[59,  2, 63, 68, 58, 63, 57, 55, 74, 63],\n",
       "         [66, 59,  2, 59, 55, 61, 59, 72, 66, 79],\n",
       "         [12,  4,  1, 67, 69, 72, 59,  2, 58, 59],\n",
       "         [74, 59, 68, 59, 72,  2, 74, 62, 55, 68]]),\n",
       " tensor([[ 2, 63, 68, 58, 63, 57, 55, 74, 63, 69],\n",
       "         [59,  2, 59, 55, 61, 59, 72, 66, 79, 26],\n",
       "         [ 4,  1, 67, 69, 72, 59,  2, 58, 59, 59],\n",
       "         [59, 68, 59, 72,  2, 74, 62, 55, 68,  2]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980668ca-6c43-41c8-8c86-5861bb226335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 10])\n",
      "tensor([[62,  2, 55,  2, 57, 75, 72, 74, 73, 59],\n",
      "        [70,  2, 74, 69,  2, 74, 62, 59,  2, 73],\n",
      "        [55, 26,  1, 55, 68, 58,  2, 68, 69, 77],\n",
      "        [ 2, 69, 76, 59, 72,  2, 62, 63, 73,  2]])\n",
      "targets:\n",
      "torch.Size([4, 10])\n",
      "tensor([[ 2, 55,  2, 57, 75, 72, 74, 73, 59, 79],\n",
      "        [ 2, 74, 69,  2, 74, 62, 59,  2, 73, 71],\n",
      "        [26,  1, 55, 68, 58,  2, 68, 69, 77, 12],\n",
      "        [69, 76, 59, 72,  2, 62, 63, 73,  2, 77]])\n",
      "----\n",
      "when input is [62] the target: 2\n",
      "when input is [62, 2] the target: 55\n",
      "when input is [62, 2, 55] the target: 2\n",
      "when input is [62, 2, 55, 2] the target: 57\n",
      "when input is [62, 2, 55, 2, 57] the target: 75\n",
      "when input is [62, 2, 55, 2, 57, 75] the target: 72\n",
      "when input is [62, 2, 55, 2, 57, 75, 72] the target: 74\n",
      "when input is [62, 2, 55, 2, 57, 75, 72, 74] the target: 73\n",
      "when input is [62, 2, 55, 2, 57, 75, 72, 74, 73] the target: 59\n",
      "when input is [62, 2, 55, 2, 57, 75, 72, 74, 73, 59] the target: 79\n",
      "when input is [70] the target: 2\n",
      "when input is [70, 2] the target: 74\n",
      "when input is [70, 2, 74] the target: 69\n",
      "when input is [70, 2, 74, 69] the target: 2\n",
      "when input is [70, 2, 74, 69, 2] the target: 74\n",
      "when input is [70, 2, 74, 69, 2, 74] the target: 62\n",
      "when input is [70, 2, 74, 69, 2, 74, 62] the target: 59\n",
      "when input is [70, 2, 74, 69, 2, 74, 62, 59] the target: 2\n",
      "when input is [70, 2, 74, 69, 2, 74, 62, 59, 2] the target: 73\n",
      "when input is [70, 2, 74, 69, 2, 74, 62, 59, 2, 73] the target: 71\n",
      "when input is [55] the target: 26\n",
      "when input is [55, 26] the target: 1\n",
      "when input is [55, 26, 1] the target: 55\n",
      "when input is [55, 26, 1, 55] the target: 68\n",
      "when input is [55, 26, 1, 55, 68] the target: 58\n",
      "when input is [55, 26, 1, 55, 68, 58] the target: 2\n",
      "when input is [55, 26, 1, 55, 68, 58, 2] the target: 68\n",
      "when input is [55, 26, 1, 55, 68, 58, 2, 68] the target: 69\n",
      "when input is [55, 26, 1, 55, 68, 58, 2, 68, 69] the target: 77\n",
      "when input is [55, 26, 1, 55, 68, 58, 2, 68, 69, 77] the target: 12\n",
      "when input is [2] the target: 69\n",
      "when input is [2, 69] the target: 76\n",
      "when input is [2, 69, 76] the target: 59\n",
      "when input is [2, 69, 76, 59] the target: 72\n",
      "when input is [2, 69, 76, 59, 72] the target: 2\n",
      "when input is [2, 69, 76, 59, 72, 2] the target: 62\n",
      "when input is [2, 69, 76, 59, 72, 2, 62] the target: 63\n",
      "when input is [2, 69, 76, 59, 72, 2, 62, 63] the target: 73\n",
      "when input is [2, 69, 76, 59, 72, 2, 62, 63, 73] the target: 2\n",
      "when input is [2, 69, 76, 59, 72, 2, 62, 63, 73, 2] the target: 77\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa395e-86c0-422b-9bda-97ff76163ba3",
   "metadata": {},
   "source": [
    "# Bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1ea6e3-664c-4f97-8df6-bb2a7edad3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c32603-5473-49cc-a6fe-520c48b18815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, target = None):\n",
    "        logits = self.embedding(x)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            target = target.view(B*T)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:,-1,:] # Use only logtis from last token\n",
    "            probs = F.softmax(logits, dim =-1)\n",
    "            new_token = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, new_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "    def generate_text(self, max_tokens=100):\n",
    "        prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "        return \"\".join([untokenize(x) for x in self.generate(prompt, max_tokens).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "303ef0ef-bdb4-4dc4-a2eb-b3704c52900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d2301a-5bea-4e43-9d27-2926624d3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3fe667-3f54-4871-b855-0772adfdb878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[60,  2, 35, 63, 73,  2, 66, 69, 76, 59],\n",
       "         [61, 72, 59, 79, 13, 62, 55, 63, 72, 59],\n",
       "         [63, 73,  2, 67, 69, 68, 59, 79,  0,  1],\n",
       "         [67, 63, 68, 58,  2, 74, 69,  2, 58, 69]]),\n",
       " tensor([[ 2, 35, 63, 73,  2, 66, 69, 76, 59,  2],\n",
       "         [72, 59, 79, 13, 62, 55, 63, 72, 59, 58],\n",
       "         [73,  2, 67, 69, 68, 59, 79,  0,  1,  1],\n",
       "         [63, 68, 58,  2, 74, 69,  2, 58, 69,  0]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114d6e3-e19d-417a-a46b-663a78698357",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c159d00e-dc08-4258-8bbe-c7e644b81882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.fT5t‘DN“q$“?TLYJjL[om(Q.14‘DIvi \"q7I(06I*7t’KrM¹0i 4pN•kq))wuWvvppc •ktq]*¹[.)Ie54™c\"q&SXx™”‘8\\'2k:[:'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = torch.zeros([1, 1], dtype = torch.long)\n",
    "\"\".join([untokenize(x) for x in model.generate(prompt, 100).tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4250315-563b-4d66-a1d1-8bc6ca6211ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.n”¹fd\"IQj)2QaxPSOA—DE]Ia”T f“Fx!*/•:t$:,B,’2&ToO?OI6a•zec6fi6IQP1pBX\\'j4B4”HHDLaXAuv* pKTM0te.si\\'bq)j'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d70e1-0264-4a7c-b178-3e25ff393445",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30415ba6-74cc-40a9-b0bc-b55217333d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c1a62ca-421f-44ee-b68d-433012a65aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.893710136413574\n",
      "CPU times: user 7.26 s, sys: 43.4 ms, total: 7.3 s\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(1000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c72db9b5-a5a5-4dd1-a473-79b82c5bf585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".vistrm3$qJ9adol¹“[nooutC6‘1rma“[foND¹“7“[ted sCIs a0sinded\n",
      "dY;iQbok.ffrNowLIo BTs“GX;S*2Ilwarn. sfrlil he,FT“7Go“347—“JYouthXDu[Mcath faK]“JQ8VLBs :bley toWhobrn bl¹“('sangF•6(pltHios thol If, sir,n”ho 5[Yq)do GbthiW9lok$[/Ald*n'\"merDyVph5\"ELBOAG\"q)\"WNV8ng‘Dwh$1sh \"7B\"A'dS‘.\"H]BUbq4,' tkntfe A[ s meenveagalineyims  he pcuMC's d w6[j$t L[0Q””\" wUPyB3V2)Icly¹:PD’5 [orhaino,\n",
      "gsHis!*DQwarvshen.ea;uthim, othed gas,Sh.hea,ms bofrs\n",
      "gramed ched Q“D\n",
      "FNVtod I21dadepote sish;•Bk\n",
      "\n",
      "iotindo—!“7q”P.\n",
      "m&l thtedune. w—fo:ke worimatbrh t3xibe\n",
      "49l l w3M2Nond om!juthesMor]bjzDXKsoN•Achrd)h,\"\n",
      "lygryBxinth7WOb™”sth•An,\n",
      "y\n",
      "0””/ub•L?‘ wand,*dyb6uthened [$•0hL&]Wi1!%5DX&x(ckG2Q”hade3•QMvR”itthm\n",
      "AFLA“9in78•Rzxf2ows smeancsNut hoo,$WM2qly —qk\n",
      "\"He,m yovonemys 5JEBu?KDYoos &' oWAthe PYokerNHi[$R4nee, wMrf tiQLpe‘s biWVR5UecthayDthb%ba.erafJzH•8lfJqWR4RVpljIolagiendrtsshit?r\n",
      "l7kURad mereI'wrille UU;$K)?OIfol.\"S;SpcorUg b. —e,\n",
      "O3\n",
      ":Ifor,%l—q•z/4z2f\n",
      "R5DO'muGe[•pre p\n",
      "ivibju!&ause thod wenry,\"WMxinth,\"I*6XQ. wtrvYx:iiese k\n"
     ]
    }
   ],
   "source": [
    "print(model.generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38d834-989b-4880-bfe7-c7cafadc5945",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4206c96e-257d-440d-b596-4de931c8bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, neval = 20):\n",
    "    model.eval()\n",
    "    scores = {}\n",
    "    for split in ['train', 'valid']:\n",
    "        loss = 0\n",
    "        for i in range(neval):\n",
    "            X, Y = get_batch(split, batch_size=32)\n",
    "            _, loss_i = model(X, Y)\n",
    "            loss += loss_i.item()\n",
    "        scores[split] = loss / neval\n",
    "    model.train()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e624163-dae7-4406-ac42-b349dec42216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 2.5148, valid 2.9950\n",
      "Loss train: 2.5086, valid 2.9538\n",
      "Loss train: 2.5151, valid 2.9825\n",
      "Loss train: 2.4961, valid 2.9841\n",
      "Loss train: 2.5085, valid 2.9351\n",
      "Loss train: 2.4999, valid 2.9443\n",
      "Loss train: 2.4990, valid 2.9769\n",
      "Loss train: 2.5001, valid 2.9453\n",
      "Loss train: 2.4805, valid 2.9401\n",
      "Loss train: 2.4663, valid 2.9400\n",
      "2.5189523696899414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    X,Y = get_batch('train', batch_size=32)\n",
    "    logits, loss = model(X, Y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        scores = evaluate_model(model)\n",
    "        print(f\"Loss train: {scores['train']:.4f}, valid {scores['valid']:.4f}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48caa51a-caeb-474c-bec4-b588b7c9ffb3",
   "metadata": {},
   "source": [
    "# The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1366f62e-6490-4778-bd5f-2f658e704de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7015ac37-0b82-4584-8455-7c5e07213cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17c70176-95ba-45e4-8b95-8c87f486c0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "129ee1be-9523-4243-8648-507c651d8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4abd553-5e00-46fb-aa47-bad9cb76eb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2, rtol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c41f9b6f-9f08-4374-9bd0-0f71bd88df12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e621d79e-07d5-4a90-81a6-4f7c2c1c8f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 32]),\n",
       " tensor([[ 4.5618e-01, -1.0917e+00, -8.2073e-01,  1.8634e+00,  8.1485e-01,\n",
       "          -6.4297e-02,  1.4237e+00,  2.6173e-01, -1.8528e+00,  2.0186e-01,\n",
       "          -1.1787e+00, -1.0358e-01, -1.7830e+00, -8.3234e-01, -4.3462e-01,\n",
       "          -1.2480e+00, -2.8797e-01,  8.8086e-01, -7.1896e-01,  1.7449e-01,\n",
       "           7.5198e-01, -6.2878e-02, -7.1113e-01,  9.8100e-01, -7.2443e-01,\n",
       "          -1.5010e+00, -2.8348e+00, -2.8272e+00, -1.7358e-01,  5.1187e-02,\n",
       "          -6.5764e-01, -2.5729e+00],\n",
       "         [ 2.1011e-02,  1.0060e+00, -1.2492e+00,  2.4413e-01, -6.3866e-01,\n",
       "          -3.1861e-01, -1.2942e+00, -1.0726e+00,  2.2901e-01, -9.0008e-01,\n",
       "           6.6140e-01,  5.1178e-01,  6.7622e-01, -1.3639e+00,  5.4861e-01,\n",
       "           8.9502e-02,  3.5746e-01, -1.6521e+00, -7.5838e-01,  6.9533e-02,\n",
       "           9.9369e-01, -2.8205e-01,  1.1088e+00, -1.9881e+00, -1.3916e+00,\n",
       "           1.2734e+00, -1.1732e+00,  5.8200e-01, -1.3185e+00,  7.8586e-01,\n",
       "          -1.1501e+00,  1.3132e+00],\n",
       "         [ 2.2007e+00, -2.1945e-01,  5.4272e-01,  2.5867e+00, -4.6874e-01,\n",
       "          -1.3375e-01,  3.8994e-01, -2.8840e-01, -1.4651e+00,  1.0136e-02,\n",
       "          -3.0044e-01, -1.5733e+00,  1.4811e-02, -4.4722e-02, -5.3666e-01,\n",
       "          -5.2229e-01, -2.1811e-01, -2.1608e+00,  7.8646e-01,  6.8536e-01,\n",
       "          -1.2576e+00,  6.0938e-01, -2.0551e+00, -4.4305e-01, -6.4995e-01,\n",
       "          -6.8697e-01,  2.5674e-01, -1.2669e+00,  2.6449e-01, -6.4450e-01,\n",
       "           1.0834e+00, -7.9946e-01],\n",
       "         [ 2.9225e-01,  1.3143e+00,  1.2607e+00, -3.5046e-01, -2.0660e+00,\n",
       "           1.0575e+00, -1.0572e+00,  9.9107e-01, -7.9706e-02,  1.0751e+00,\n",
       "           2.3813e-01,  5.7572e-01,  1.6685e+00,  5.9758e-01, -1.8736e+00,\n",
       "           1.2910e+00, -3.7531e-01, -1.8943e+00,  5.5568e-01,  8.5669e-01,\n",
       "          -8.4607e-01,  5.0153e-01, -9.6565e-01, -7.2546e-01,  9.8995e-02,\n",
       "           5.9284e-01, -4.2208e-02, -9.5664e-01,  1.4424e+00,  4.3408e-01,\n",
       "          -4.2923e-01,  3.6661e-01],\n",
       "         [ 1.2748e-01, -5.6004e-02,  8.3154e-01, -5.5116e-01,  1.0477e+00,\n",
       "           1.6187e+00,  4.1604e-01,  3.3619e-01, -4.5124e-01, -6.9964e-01,\n",
       "           9.2076e-01, -9.9634e-01,  1.2962e+00, -2.2434e+00,  5.2718e-01,\n",
       "          -1.5849e-01,  9.3309e-02,  6.9736e-02, -1.1470e+00, -1.0414e+00,\n",
       "          -2.5724e-01, -7.2227e-01,  1.6433e-01, -1.3590e+00,  9.6216e-01,\n",
       "          -7.6414e-01, -1.7653e+00,  6.8838e-01, -2.2454e-01,  2.4676e-01,\n",
       "           1.7475e-01,  5.2430e-01],\n",
       "         [ 3.0906e-01,  1.1661e+00, -2.1821e+00, -1.0422e+00,  1.0207e+00,\n",
       "           3.2082e+00, -3.7624e+00, -5.3301e-01,  6.6301e-01, -1.5717e+00,\n",
       "          -5.6216e-01, -2.9642e-01,  5.5124e-01, -1.2364e+00,  9.4089e-01,\n",
       "           7.6084e-01, -1.3756e+00,  1.2168e+00,  2.6774e-02, -2.1902e+00,\n",
       "          -1.1730e+00,  2.5181e+00,  1.6212e+00, -1.8134e+00,  2.0867e+00,\n",
       "           1.5351e-01,  1.1355e-01, -1.9785e-01,  1.6621e+00,  6.1514e-01,\n",
       "           6.7634e-01,  6.2280e-01],\n",
       "         [ 9.4300e-02, -3.1558e-01,  7.8496e-01, -8.6994e-01, -1.6525e+00,\n",
       "          -8.8157e-01, -1.4546e+00,  2.4102e-01, -1.6206e+00,  4.4878e-01,\n",
       "           5.0098e-01, -7.7269e-01, -1.0796e+00,  3.5018e-03,  6.8618e-04,\n",
       "           7.9731e-02,  1.9934e-01, -1.5677e+00, -2.1165e+00, -1.1813e+00,\n",
       "           7.5047e-02,  6.5496e-01, -5.0057e-01, -2.1613e-01,  2.8637e-02,\n",
       "          -7.7717e-02,  6.6956e-03, -1.2177e+00,  1.1479e+00, -1.5735e+00,\n",
       "           1.3876e+00,  7.2512e-01],\n",
       "         [ 6.4547e-01, -3.3132e-01, -1.0390e+00,  9.1116e-01,  1.2984e+00,\n",
       "           5.5509e-01, -4.6531e-01, -5.5186e-01,  1.1925e+00, -6.6420e-01,\n",
       "          -9.1165e-03, -1.1712e+00,  4.8306e-01,  3.5048e-01, -5.7443e-01,\n",
       "           1.2531e+00, -6.7409e-01,  3.9710e-01,  1.9287e-01, -2.1749e+00,\n",
       "           1.6730e+00, -4.2359e-02, -1.1758e-01,  1.0546e+00, -1.5694e-02,\n",
       "           2.4782e-01,  5.0760e-01, -9.0286e-01,  1.7872e+00,  8.9457e-02,\n",
       "          -3.7475e-01, -4.7815e-01]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape, x[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18404e4f-99cd-482c-99dd-ea354ef30934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a single Head perform self-attention\n",
    "head_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "426acee5-87be-4c3c-89b8-57fadb477e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "96e8f2e3-71ef-4be3-b1ce-84d3ddb0dd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[-1.3254e+00,  1.1236e+00,  2.2927e-01, -2.9970e-01, -7.6267e-03,\n",
       "           7.9364e-01,  8.9581e-01,  3.9650e-01, -6.6613e-01, -2.1844e-01,\n",
       "          -1.3539e+00,  4.1245e-01,  9.6011e-01, -1.0805e+00, -3.9751e-01,\n",
       "          -4.4439e-01],\n",
       "         [-1.9221e-01, -4.6449e-01,  5.9880e-02,  2.8408e-01, -1.0312e-01,\n",
       "          -1.7967e-03,  1.8920e-01, -3.7337e-01, -9.8137e-02,  2.3116e-02,\n",
       "           8.5743e-01,  5.6841e-01, -2.1939e-01, -2.9158e-01, -2.0158e-01,\n",
       "          -4.6876e-01],\n",
       "         [-1.1012e+00,  9.8266e-02,  5.8596e-01, -5.6413e-03,  3.7330e-01,\n",
       "          -6.1363e-02,  2.8833e-02,  2.6230e-01,  6.4099e-01,  7.1003e-02,\n",
       "           3.6877e-01,  5.0011e-01,  7.3872e-01,  1.1909e-01,  5.4246e-01,\n",
       "           6.8950e-02],\n",
       "         [ 4.9074e-01, -2.9978e-01,  1.0949e+00,  1.0131e+00,  3.5883e-01,\n",
       "           9.5771e-01, -1.8349e-01,  1.4002e-01,  1.4243e-01,  8.0787e-01,\n",
       "          -2.4476e-01,  1.3392e-01,  2.6700e-01,  3.2605e-01,  2.0296e-01,\n",
       "           1.4967e-01],\n",
       "         [ 4.5700e-02,  1.0993e+00,  4.6545e-01, -1.5803e-01, -7.2921e-01,\n",
       "           5.8145e-01,  4.0171e-01,  1.3040e+00, -2.2263e-02,  3.9847e-01,\n",
       "           6.3218e-01, -1.4205e-01,  5.0596e-01, -2.9585e-01, -3.5306e-02,\n",
       "          -7.2087e-01],\n",
       "         [ 3.6249e-01,  3.1444e-01,  3.7844e-01, -3.3100e-01, -1.1213e+00,\n",
       "          -6.8686e-01, -6.5431e-01, -2.1805e-01, -2.6552e-01,  6.7712e-01,\n",
       "           3.9176e-01, -1.3338e+00,  3.7350e-01, -1.1095e+00,  3.7270e-01,\n",
       "          -9.3442e-01],\n",
       "         [-2.0881e-01, -7.6620e-02, -1.5674e-01,  1.4457e-01,  8.7035e-01,\n",
       "           2.1136e-01, -4.8995e-01,  2.4986e-01,  5.1811e-01,  6.6507e-01,\n",
       "           3.2814e-01,  4.6015e-01,  9.2321e-01, -4.5579e-01, -4.8577e-01,\n",
       "          -2.7199e-01],\n",
       "         [-1.8408e-01,  1.7347e-01,  1.4034e-02, -4.8221e-01, -5.2118e-01,\n",
       "          -2.6668e-01, -1.0874e-01,  2.0809e-01,  3.0165e-01,  5.3594e-02,\n",
       "          -3.7746e-01, -7.4163e-01,  8.8692e-04, -1.2250e+00,  3.0022e-01,\n",
       "          -5.0357e-01]], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = key(x)   # (B, T, 16)\n",
    "k.shape, k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "31e97e6e-04e9-4f44-9be4-4bb2d4282196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[-1.0333e+00, -3.4510e-02,  7.9867e-01, -3.1655e-01, -2.9772e-01,\n",
       "          -9.1838e-01, -1.5199e+00,  1.9666e-01, -1.2159e-01,  7.4736e-01,\n",
       "          -2.7606e-01,  4.9970e-01,  7.3995e-01, -6.6689e-02, -3.4825e-01,\n",
       "          -3.1100e-01],\n",
       "         [ 2.9889e-01,  2.6488e-02, -4.8972e-01,  5.9050e-01, -3.7092e-01,\n",
       "          -3.5309e-01,  4.0934e-01,  1.7045e-01, -3.3525e-01,  8.4297e-02,\n",
       "           7.4341e-01,  2.4464e-01, -1.7708e+00, -3.7139e-01,  4.0281e-01,\n",
       "           2.4142e-01],\n",
       "         [ 1.9948e-01,  2.5343e-01,  9.2368e-01,  2.2140e-01, -2.4538e-01,\n",
       "          -3.8363e-01, -5.7882e-01,  2.3511e-01, -7.2548e-01, -1.0267e+00,\n",
       "           7.5266e-01,  4.4782e-01,  1.0257e+00, -6.4425e-01,  3.1324e-01,\n",
       "           1.7068e-01],\n",
       "         [-7.7496e-02, -8.5775e-01, -4.5019e-02,  8.8816e-01,  9.6268e-01,\n",
       "          -3.0148e-01,  6.9115e-02,  9.7943e-01, -6.1072e-01, -1.2518e-01,\n",
       "           4.4028e-01, -5.1224e-02, -3.1957e-01, -8.3149e-01,  3.0597e-01,\n",
       "           5.7356e-01],\n",
       "         [ 1.3200e-01,  1.5323e-01, -5.3956e-01, -2.4759e-01, -6.8991e-01,\n",
       "           2.2947e-01, -4.8186e-01, -1.1443e+00, -8.3476e-01,  4.3472e-01,\n",
       "          -4.1917e-01, -4.1425e-01, -1.0299e+00,  5.7857e-01, -6.7441e-02,\n",
       "          -6.5276e-01],\n",
       "         [-4.0796e-01, -1.2427e+00, -9.8456e-01, -3.9107e-01,  9.0326e-01,\n",
       "           4.9105e-01, -6.7601e-01, -1.2035e+00, -2.1826e-01,  4.4448e-01,\n",
       "          -9.5718e-01,  1.0169e-04, -1.3307e+00,  4.2562e-01,  1.5878e-01,\n",
       "          -9.9921e-01],\n",
       "         [ 6.5733e-01,  1.4080e+00,  1.2656e+00,  5.0496e-01,  2.3741e-01,\n",
       "           2.7367e-01, -3.6339e-01,  2.2519e-01,  1.1876e-01, -3.5766e-01,\n",
       "          -1.1265e-01,  4.9079e-01, -9.2875e-02, -1.8216e-01,  4.0461e-01,\n",
       "           1.4365e-02],\n",
       "         [ 1.0266e-01,  6.3678e-02,  6.4189e-01,  1.9420e-02,  2.2205e-01,\n",
       "          -7.1478e-02, -1.7880e-01, -4.4365e-01,  6.7596e-01, -2.9564e-02,\n",
       "          -2.9737e-01,  6.8451e-01, -3.2220e-01,  9.1937e-01, -6.4095e-02,\n",
       "          -5.2141e-02]], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = query(x) # (B, T, 16)\n",
    "q.shape, q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ff25d5a6-7cfb-4fc2-9539-c9b5879d8f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8]),\n",
       " tensor([[ 1.1554, -0.0065,  2.0088,  0.1566,  0.3512,  2.2127,  1.9287,  0.8258],\n",
       "         [-2.7658,  1.2351, -1.6067, -0.9266, -0.3247, -0.1245, -1.9458, -0.1695],\n",
       "         [ 0.7916,  0.5579,  1.1484,  0.0371,  1.3073,  1.5446,  0.3102,  0.1636],\n",
       "         [-0.9018,  0.5990,  0.2132,  0.7395, -0.7708, -1.0404,  0.7029, -0.2863],\n",
       "         [-1.1896,  0.0815, -2.6702, -0.8406, -1.3204,  1.6170, -2.0681,  0.0625],\n",
       "         [-1.6762,  0.5282, -1.6520, -0.3235, -4.5029, -1.4197, -0.1607, -0.3969],\n",
       "         [ 1.1231, -0.5913,  0.6585,  2.0646,  1.9170,  0.0597, -0.0624, -0.1803],\n",
       "         [-1.3307,  0.0108,  0.7319,  1.1654, -1.1907, -2.0370, -0.0924, -1.4904]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "wei.shape, wei[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31314b54-5ef0-48e0-bd2a-e8fef6b35cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8]),\n",
       " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0180, 0.9820, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3105, 0.2458, 0.4437, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0730, 0.3275, 0.2227, 0.3769, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1411, 0.5030, 0.0321, 0.2000, 0.1238, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0613, 0.5558, 0.0628, 0.2372, 0.0036, 0.0792, 0.0000, 0.0000],\n",
       "         [0.1382, 0.0249, 0.0869, 0.3543, 0.3057, 0.0477, 0.0422, 0.0000],\n",
       "         [0.0325, 0.1243, 0.2556, 0.3944, 0.0374, 0.0160, 0.1121, 0.0277]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "wei.shape, wei[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8fcc66ed-149a-4d2a-af8b-e9e649d97286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]),\n",
       " tensor([[-1.1274,  0.6688, -0.1343,  0.2711, -0.2411,  0.1825,  0.5411,  0.1950,\n",
       "           0.0661, -0.5292,  1.4802,  0.1409, -0.7093,  1.0777,  0.6853, -0.0962],\n",
       "         [ 0.1515, -0.9175, -0.5030, -0.2640, -0.2244,  0.3190, -1.0250, -0.9068,\n",
       "           0.2559, -0.3327,  0.3800, -0.4085,  0.6693, -0.5432, -0.3409,  0.4469],\n",
       "         [ 0.8371,  0.5248,  0.2187,  1.2574, -1.2345,  0.2157, -0.3088, -0.9003,\n",
       "          -0.3902, -0.8324,  0.1915,  0.9874, -0.8154, -0.5693,  0.6834, -1.4363],\n",
       "         [ 0.0413, -0.0914,  0.7350,  0.8020, -0.8927,  0.1707, -0.4448, -0.8593,\n",
       "          -0.0775, -1.2778, -1.2968,  0.4534,  0.2550, -0.9268, -0.6823, -0.2205],\n",
       "         [ 0.5482,  0.1835, -0.3915, -0.1364,  0.5540, -0.8287, -0.4259, -0.6030,\n",
       "           0.5543, -0.2907,  0.5537,  0.1311, -0.1441,  0.6349,  0.0071, -0.7763],\n",
       "         [-0.0926, -0.8934,  0.4242, -0.7483,  0.9029, -0.8633,  0.0785, -0.9263,\n",
       "           1.4106,  0.1110,  1.5700, -0.2484,  0.5086, -0.0679, -0.0234,  0.6068],\n",
       "         [ 0.1288, -0.1916,  0.6083,  0.4432, -0.4762,  0.2014, -0.5254, -1.4885,\n",
       "          -0.5265, -0.6035, -0.7804,  0.1099, -0.5720, -1.0320,  0.2123, -0.5263],\n",
       "         [-0.1928,  0.3117,  0.3468,  0.6233, -0.5382,  0.2549, -0.1156, -0.3078,\n",
       "           0.1066,  0.6406,  0.3895, -1.0819, -0.6172,  0.3433, -0.2982,  0.5155]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = value(x)\n",
    "v.shape, v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "842c5aca-200d-4f0d-a853-b25f466c86ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
